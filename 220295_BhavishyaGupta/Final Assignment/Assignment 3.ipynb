{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL ASSIGNMENT :\n",
    "#### Dataset: Red Wine Quality\n",
    "\n",
    "##### The dataset is related to the red variant of \"Vinho Verde\" wine. It contains 1599 data points where features are the physicochemical properties and the target value is quality which is an integer score ranging from 0-10. Your task is to classify if the wine provided is good based on its physicochemical properties.\n",
    "\n",
    "##### (i) Create a new column on the dataset with binary values (i.e, 0 or 1) telling whether the wine is of good quality or not. You can categorise wines with quality>=7 to be of good quality. Drop the original ‘quality’ column.\n",
    "\n",
    "##### (ii) Perform the data pre-processing steps that you feel are important for the given dataset.\n",
    "\n",
    "##### (iii) Apply following classification algorithms on the given dataset (you are allowed to use scikit-learn library until not specified ‘from scratch’):\n",
    "\n",
    " ##### Logistic Regression\n",
    " ##### K-Nearest Neighbors\n",
    " ##### Decision Trees Classifier\n",
    " ##### Random Forest Classifier\n",
    " ##### Logistic Regression from Scratch \n",
    "\n",
    "##### (iv) Evaluate all your models based on the accuracy score and f1 score obtained on the test dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.8656\n",
      "F1 Score: 0.3768\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "Accuracy: 0.8812\n",
      "F1 Score: 0.5128\n",
      "\n",
      "Decision Trees Classifier:\n",
      "Accuracy: 0.8781\n",
      "F1 Score: 0.5618\n",
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.9125\n",
      "F1 Score: 0.6500\n",
      "\n",
      "Logistic Regression from scratch:\n",
      "Accuracy: 0.8562\n",
      "F1 Score: 0.5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "# (i) Create a new column for good quality\n",
    "df['good_quality'] = (df['quality'] >= 7).astype(int)\n",
    "\n",
    "# Drop the original 'quality' column\n",
    "df.drop('quality', axis=1, inplace=True)\n",
    "\n",
    "# (ii) Data pre-processing steps\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('good_quality', axis=1)\n",
    "y = df['good_quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler() \n",
    "# Fit the scaler on the training data and simultaneously transform the features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Transform the test data using the previously fitted scaler (ensures same scaling parameters as training data)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# (iii) Apply classification algorithms\n",
    "# Logistic Regression\n",
    "\n",
    "# Create a Logistic Regression model instance\n",
    "logistic_model = LogisticRegression()\n",
    "# Train the Logistic Regression model on the scaled training data\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "# Use the trained Logistic Regression model to make predictions on the scaled test data\n",
    "logistic_preds = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "\n",
    "# Create an instance of the K-Nearest Neighbors (KNN) classifier model\n",
    "knn_model = KNeighborsClassifier()\n",
    "# Train the KNN model using the scaled training data and corresponding target values\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "# Use the trained KNN model to make predictions on the scaled test data\n",
    "knn_preds = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Decision Trees Classifier\n",
    "\n",
    "# Create an instance of the Decision Tree classifier model\n",
    "tree_model = DecisionTreeClassifier()\n",
    "# Train the Decision Tree model using the scaled training data and corresponding target values\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "# Use the trained Decision Tree model to make predictions on the scaled test data\n",
    "tree_preds = tree_model.predict(X_test_scaled)\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "# Create an instance of the Random Forest classifier model\n",
    "rf_model = RandomForestClassifier()\n",
    "# Train the Random Forest model using the scaled training data and corresponding target values\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "# Use the trained Random Forest model to make predictions on the scaled test data\n",
    "rf_preds = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Define a custom Logistic Regression class from scratch\n",
    "class LogisticRegressionScratch:\n",
    "    def __init__(self, learning_rate=0.0001, num_iterations=1500):\n",
    "        # Initialize the logistic regression model with default or user-defined learning rate and number of iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        # Initialize weights and bias to None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        # Sigmoid activation function used to squash values between 0 and 1\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Get the number of samples (m) and features (n) from the input data X\n",
    "        m, n = X.shape\n",
    "        # Initialize weights to zeros and bias to zero\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Calculate the predicted values\n",
    "            y_pred = self.sigmoid(np.dot(X, self.weights) + self.bias)\n",
    "\n",
    "            # Calculate the gradients\n",
    "            dw = (1 / m) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / m) * np.sum(y_pred - y)\n",
    "\n",
    "            # Update weights and bias using gradient descent\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Use the trained weights and bias to make predictions\n",
    "        return np.round(self.sigmoid(np.dot(X, self.weights) + self.bias))\n",
    "\n",
    "\n",
    "# Train the Logistic Regression model from scratch\n",
    "\n",
    "# Create an instance of the Logistic Regression model from scratch\n",
    "lr_scratch = LogisticRegressionScratch(learning_rate=0.0001, num_iterations=1500)\n",
    "# Train the Logistic Regression model from scratch using the scaled training data\n",
    "lr_scratch.fit(X_train_scaled, y_train)\n",
    "# Use the trained Logistic Regression model from scratch to make predictions on the scaled test data\n",
    "lr_scratch_preds = lr_scratch.predict(X_test_scaled)\n",
    "\n",
    "# (iv) Evaluate models\n",
    "# Define a function to print evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    # Calculate accuracy using accuracy_score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # Calculate F1 score using f1_score\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    # Print model evaluation metrics\n",
    "    print(f\"{model_name}:\\nAccuracy: {accuracy:.4f}\\nF1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "# Evaluate and print performance metrics for Logistic Regression model\n",
    "evaluate_model(y_test, logistic_preds, \"Logistic Regression\")\n",
    "# Evaluate and print performance metrics for K-Nearest Neighbors model\n",
    "evaluate_model(y_test, knn_preds, \"K-Nearest Neighbors\")\n",
    "# Evaluate and print performance metrics for Decision Trees Classifier model\n",
    "evaluate_model(y_test, tree_preds, \"Decision Trees Classifier\")\n",
    "# Evaluate and print performance metrics for Random Forest Classifier model\n",
    "evaluate_model(y_test, rf_preds, \"Random Forest Classifier\")\n",
    "# Evaluate and print performance metrics for Logistic Regression from scratch model\n",
    "evaluate_model(y_test, lr_scratch_preds, \"Logistic Regression from scratch\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
